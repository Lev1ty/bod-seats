{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyspark\n",
    "import sklearn\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from IPython.display import display\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "<pyspark.sql.session.SparkSession at 0x7fbc8d4f7820>",
      "text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://130.113.183.13:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.1.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>bod-seats</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = (\n",
    "    pyspark.sql.SparkSession.builder\n",
    "    .master(\"local[*]\")\n",
    "    .appName(\"bod-seats\")\n",
    "    .config(\"spark.driver.memory\", \"16g\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- text: struct (nullable = true)\n",
      " |    |-- input_ids: array (nullable = true)\n",
      " |    |    |-- element: short (containsNull = true)\n",
      " |    |-- attention_mask: array (nullable = true)\n",
      " |    |    |-- element: short (containsNull = true)\n",
      " |    |-- token_type_ids: array (nullable = true)\n",
      " |    |    |-- element: short (containsNull = true)\n",
      " |    |-- labels: byte (nullable = true)\n",
      "\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- text: struct (nullable = true)\n",
      " |    |-- input_ids: array (nullable = true)\n",
      " |    |    |-- element: short (containsNull = true)\n",
      " |    |-- attention_mask: array (nullable = true)\n",
      " |    |    |-- element: short (containsNull = true)\n",
      " |    |-- token_type_ids: array (nullable = true)\n",
      " |    |    |-- element: short (containsNull = true)\n",
      " |    |-- labels: byte (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = spark.read.format(\"parquet\").load(\"train.parquet\")\n",
    "train = train.withColumn(\"label\", col(\"label\").astype(BooleanType()))\n",
    "train = train.withColumn(\"text\", col(\"text\").dropFields(\"length\", \"offset_mapping\", \"special_tokens_mask\"))\n",
    "train = train.withColumn(\"text\", col(\"text\").withField(\"labels\", col(\"label\").astype(ByteType()))).drop(\"label\")\n",
    "train.printSchema()\n",
    "train = train.toPandas()\n",
    "test = spark.read.format(\"parquet\").load(\"test.parquet\")\n",
    "test = test.withColumn(\"label\", col(\"label\").astype(BooleanType()))\n",
    "test = test.withColumn(\"text\", col(\"text\").dropFields(\"length\", \"offset_mapping\", \"special_tokens_mask\"))\n",
    "test = test.withColumn(\"text\", col(\"text\").withField(\"labels\", col(\"label\").astype(ByteType()))).drop(\"label\")\n",
    "test.printSchema()\n",
    "test = test.toPandas()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.df = df\n",
    "\n",
    "    def __getitem__(self, index) -> dict[str, list[int]]:\n",
    "        return self.df.loc[index, \"text\"].asDict()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.df.shape[0]\n",
    "\n",
    "train_dataset = Dataset(train)\n",
    "test_dataset = Dataset(test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.LayerNorm.weight', 'predictions.decoder.weight', 'predictions.dense.bias', 'predictions.bias', 'predictions.dense.weight']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "args = transformers.TrainingArguments(\n",
    "    output_dir=\"3_finetuning/output\",\n",
    "    num_train_epochs=8,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    logging_dir=\"3_finetuning/logging\",\n",
    "    logging_steps=64,\n",
    "    dataloader_num_workers=64,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=1024,\n",
    "    save_steps=1024,\n",
    "    fp16=True,\n",
    "    fp16_opt_level=\"O3\",\n",
    "    learning_rate=5e-5,\n",
    ")\n",
    "\n",
    "def compute_metrics(output):\n",
    "    labels = output.label_ids\n",
    "    index = labels != -100\n",
    "    labels = labels[index]\n",
    "    predictions = output.predictions.argmax(-1)[index]\n",
    "    metrics = {}\n",
    "    for average in (\"micro\", \"macro\", \"weighted\"):\n",
    "        precision, recall, f1, _ = sklearn.metrics.precision_recall_fscore_support(\n",
    "            labels, predictions, average=average)\n",
    "        metrics[f\"{average}_precision\"] = precision\n",
    "        metrics[f\"{average}_recall\"] = recall\n",
    "        metrics[f\"{average}_f1\"] = f1\n",
    "    metrics[\"accuracy\"] = sklearn.metrics.accuracy_score(labels, predictions)\n",
    "    return metrics\n",
    "\n",
    "model = transformers.AlbertForSequenceClassification.from_pretrained(\"albert-base-v2\", num_labels=2)\n",
    "tokenizer = transformers.AlbertTokenizerFast.from_pretrained(\"albert-base-v2\")\n",
    "data_collator = transformers.DataCollatorWithPadding(tokenizer=tokenizer, pad_to_multiple_of=32)\n",
    "trainer = transformers.Trainer(\n",
    "    args=args,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mlev1ty\u001B[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.30<br/>\n                Syncing run <strong style=\"color:#cdcd00\">3_finetuning/output</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/lev1ty/huggingface\" target=\"_blank\">https://wandb.ai/lev1ty/huggingface</a><br/>\n                Run page: <a href=\"https://wandb.ai/lev1ty/huggingface/runs/2vrbcggg\" target=\"_blank\">https://wandb.ai/lev1ty/huggingface/runs/2vrbcggg</a><br/>\n                Run data is saved locally in <code>/home/adam/bod-seats/wandb/run-20210516_233831-2vrbcggg</code><br/><br/>\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='2400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/2400 : < :, Epoch 0.00/8]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-6-3435b262f1ae>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/.conda/envs/bod-seats/lib/python3.9/site-packages/transformers/trainer.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self, resume_from_checkpoint, trial, **kwargs)\u001B[0m\n\u001B[1;32m   1311\u001B[0m                     \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0muse_amp\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1312\u001B[0m                         \u001B[0mscale_before\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mscaler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_scale\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1313\u001B[0;31m                         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mscaler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1314\u001B[0m                         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mscaler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1315\u001B[0m                         \u001B[0mscale_after\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mscaler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_scale\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/bod-seats/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py\u001B[0m in \u001B[0;36mstep\u001B[0;34m(self, optimizer, *args, **kwargs)\u001B[0m\n\u001B[1;32m    319\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    320\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mv\u001B[0m \u001B[0;32min\u001B[0m \u001B[0moptimizer_state\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"found_inf_per_device\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 321\u001B[0;31m             \u001B[0mretval\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    322\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    323\u001B[0m         \u001B[0moptimizer_state\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"stage\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mOptState\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSTEPPED\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/bod-seats/lib/python3.9/site-packages/torch/optim/lr_scheduler.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m                 \u001B[0minstance\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_step_count\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m                 \u001B[0mwrapped\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__get__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minstance\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcls\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 67\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mwrapped\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     68\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m             \u001B[0;31m# Note that the returned function here is no longer a bound method,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/bod-seats/lib/python3.9/site-packages/transformers/optimization.py\u001B[0m in \u001B[0;36mstep\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    343\u001B[0m                 \u001B[0;31m# Decay the first and second moment running average coefficient\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    344\u001B[0m                 \u001B[0;31m# In-place operations to update the averages at the same time\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 345\u001B[0;31m                 \u001B[0mexp_avg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmul_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbeta1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgrad\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0malpha\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1.0\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mbeta1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    346\u001B[0m                 \u001B[0mexp_avg_sq\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmul_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbeta2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maddcmul_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgrad\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1.0\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mbeta2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    347\u001B[0m                 \u001B[0mdenom\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mexp_avg_sq\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msqrt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgroup\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"eps\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}